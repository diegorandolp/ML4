{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T13:50:42.332266Z",
     "start_time": "2024-11-29T13:50:40.101064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "# import matplotlib\n",
    "# matplotlib.use('qt5agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from torchaudio.compliance.kaldi import spectrogram"
   ],
   "id": "7c8f57c5ee1de97c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T13:50:26.964449Z",
     "start_time": "2024-11-29T13:50:26.957908Z"
    }
   },
   "cell_type": "code",
   "source": "plt.close('all')",
   "id": "c7b9c67525cc1145",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN with images of spectrograms",
   "id": "bdeb48bae32ff5d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explore noWhale",
   "id": "6a109a82f945bc22"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-29T13:50:44.596787Z",
     "start_time": "2024-11-29T13:50:44.589991Z"
    }
   },
   "source": [
    "# audio NoWhale\n",
    "waveform_noWhale, sr_noWhale = torchaudio.load(r'.\\train\\train\\0.wav')\n",
    "\n",
    "print(type(waveform_noWhale))\n",
    "print(type(sr_noWhale))\n",
    "print(waveform_noWhale.shape)\n",
    "# 2000 data points per second, in total 4000 data points\n",
    "print(sr_noWhale)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'int'>\n",
      "torch.Size([1, 4000])\n",
      "2000\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-29T13:50:46.229392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(waveform_noWhale.t().numpy())"
   ],
   "id": "4880bacd6cc777c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x206616c5f10>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:35:47.637137Z",
     "start_time": "2024-11-29T08:35:47.605995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Spectrogram\n",
    "spectrogram_noWhale = torchaudio.transforms.Spectrogram()(waveform_noWhale)\n",
    "# plot the spectrogram\n",
    "plt.figure()\n",
    "# scale the values with log2 and then select the first channel\n",
    "plt.imshow(spectrogram_noWhale.log2()[0,:,:].numpy(), cmap='viridis')"
   ],
   "id": "156f829480097ea3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1933c6f37d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Explore RightWhale",
   "id": "2595de5e840e2b16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:35:50.060397Z",
     "start_time": "2024-11-29T08:35:50.044230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# audio RightWhale\n",
    "waveform_rightWhale, sr_rightWhale = torchaudio.load(r'.\\train\\train\\1.wav')\n",
    "\n",
    "print(type(waveform_rightWhale))\n",
    "print(type(sr_rightWhale))\n",
    "print(waveform_rightWhale.shape)\n",
    "# 2000 data points per second, in total 4000 data points\n",
    "print(sr_rightWhale)\n",
    "\n"
   ],
   "id": "4a7b1f9fcc859425",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'int'>\n",
      "torch.Size([1, 4000])\n",
      "2000\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:35:52.192233Z",
     "start_time": "2024-11-29T08:35:52.174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(waveform_rightWhale.t().numpy())\n"
   ],
   "id": "ac3943f4e7e708af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1933fa65460>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:35:53.640747Z",
     "start_time": "2024-11-29T08:35:53.618482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Spectrogram\n",
    "spectrogram_rightWhale = torchaudio.transforms.Spectrogram()(waveform_rightWhale)\n",
    "# plot the spectrogram\n",
    "plt.figure()\n",
    "# scale the values with log2 and then select the first channel\n",
    "plt.imshow(spectrogram_rightWhale.log2()[0,:,:].numpy(), cmap='viridis')\n"
   ],
   "id": "67b5f2ffda5b8e44",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1933fa96bd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "2114a13bf0c228f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:35:55.493884Z",
     "start_time": "2024-11-29T08:35:55.466864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# collect all the paths in the train folder\n",
    "sound_files = os.listdir(r'.\\train\\train')\n",
    "df_labels = pd.read_csv(r'.\\train.csv')\n",
    "print(len(sound_files))"
   ],
   "id": "2b77bfc007e3519a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10944\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:35:57.403192Z",
     "start_time": "2024-11-29T08:35:57.394413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get labels\n",
    "train_labels = df_labels['class'].to_numpy()\n",
    "print(train_labels[:10])\n",
    "print(len(train_labels))"
   ],
   "id": "6c60e0148565ed27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NoWhale' 'RightWhale' 'NoWhale' 'NoWhale' 'NoWhale' 'NoWhale'\n",
      " 'RightWhale' 'NoWhale' 'NoWhale' 'RightWhale']\n",
      "10934\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:35:59.851625Z",
     "start_time": "2024-11-29T08:35:59.842361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove the audios that are not valid\n",
    "idx_labeled_audio_files = df_labels['idx'].to_numpy()\n",
    "available_audio_files = []\n",
    "for file in sound_files:\n",
    "    try:\n",
    "        idx = int(file.split('.')[0])\n",
    "        available_audio_files.append(idx)\n",
    "    except:\n",
    "        print(\"Invalid file: \", file)"
   ],
   "id": "2f867cc5c6ac52ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid file:  8675(1).wav\n",
      "Invalid file:  8676(1).wav\n",
      "Invalid file:  8677(1).wav\n",
      "Invalid file:  8678(1).wav\n",
      "Invalid file:  8679(1).wav\n",
      "Invalid file:  868(1).wav\n",
      "Invalid file:  8680(1).wav\n",
      "Invalid file:  8681(1).wav\n",
      "Invalid file:  8682(1).wav\n",
      "Invalid file:  8684(1).wav\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:36:02.304222Z",
     "start_time": "2024-11-29T08:36:02.298690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "available_audio_files = sorted(available_audio_files)\n",
    "print(available_audio_files[:5])"
   ],
   "id": "679163c3a400e924",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:36:03.244952Z",
     "start_time": "2024-11-29T08:36:03.230291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split the valid audio files into noWhale and RightWhale\n",
    "noWhale_paths = []\n",
    "rightWhale_paths = []\n",
    "# assign the paths to the corresponding label\n",
    "for idx in available_audio_files:\n",
    "    if train_labels[idx] == 'NoWhale':\n",
    "        noWhale_paths.append(idx)\n",
    "    elif train_labels[idx] == 'RightWhale':\n",
    "        rightWhale_paths.append(idx)\n",
    "    else:\n",
    "        print(\"Invalid label: \", train_labels[idx])\n",
    "\n",
    "print(len(noWhale_paths))\n",
    "print(len(rightWhale_paths))"
   ],
   "id": "23d7d692f474d51b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5467\n",
      "5467\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:36:06.042530Z",
     "start_time": "2024-11-29T08:36:06.008702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the complete path of the valid audio files\n",
    "noWhale_paths = [os.path.join(r'.\\train\\train', str(file) + '.wav') for file in noWhale_paths] \n",
    "rightWhale_paths = [os.path.join(r'.\\train\\train', str(file) + '.wav') for file in rightWhale_paths]\n",
    "print(noWhale_paths[:5])\n",
    "print(rightWhale_paths[:5])"
   ],
   "id": "2862960e37edd943",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.\\\\train\\\\train\\\\0.wav', '.\\\\train\\\\train\\\\2.wav', '.\\\\train\\\\train\\\\3.wav', '.\\\\train\\\\train\\\\4.wav', '.\\\\train\\\\train\\\\5.wav']\n",
      "['.\\\\train\\\\train\\\\1.wav', '.\\\\train\\\\train\\\\6.wav', '.\\\\train\\\\train\\\\9.wav', '.\\\\train\\\\train\\\\10.wav', '.\\\\train\\\\train\\\\14.wav']\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Process data : Get images",
   "id": "be3e16a99718d852"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:36:09.031370Z",
     "start_time": "2024-11-29T08:36:09.020493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists(r'.\\train_images_spectrogram'):\n",
    "    os.makedirs(r'.\\train_images_spectrogram\\noWhale')\n",
    "    os.makedirs(r'.\\train_images_spectrogram\\rightWhale')"
   ],
   "id": "197197e1c463c97c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:36:43.010366Z",
     "start_time": "2024-11-29T08:36:30.297692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save the spectrogram images of the noWhale\n",
    "\n",
    "for j, path in enumerate(noWhale_paths):\n",
    "    if j % 1000 == 0:\n",
    "        print(j)\n",
    "    idx = int(path.split('\\\\')[-1].split('.')[0])\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "    \n",
    "    spectrogram_noWhale = torchaudio.transforms.Spectrogram()(waveform)\n",
    "    spectrogram_path = os.path.join(r'.\\train_images_spectrogram\\noWhale', str(idx) + '.png')\n",
    "    # scale the values with log2 and then select the first channel\n",
    "   \n",
    "    plt.imsave(spectrogram_path, spectrogram_noWhale.log2()[0,:,:].numpy(), cmap='viridis')\n",
    "    j = j + 1\n"
   ],
   "id": "37d96556a499228",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T08:39:41.807376Z",
     "start_time": "2024-11-29T08:39:27.209377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# save the spectrogram images of the rightWhale\n",
    "\n",
    "for j, path in enumerate(rightWhale_paths):\n",
    "    if j % 1000 == 0:\n",
    "        print(j)\n",
    "    idx = int(path.split('\\\\')[-1].split('.')[0])\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "\n",
    "    spectrogram_rightWhale = torchaudio.transforms.Spectrogram()(waveform)\n",
    "    spectrogram_path = os.path.join(r'.\\train_images_spectrogram\\rightWhale', str(idx) + '.png')\n",
    "    # scale the values with log2 and then select the first channel\n",
    "\n",
    "    plt.imsave(spectrogram_path, spectrogram_rightWhale.log2()[0,:,:].numpy(), cmap='viridis')\n",
    "    j = j + 1\n",
    "\n"
   ],
   "id": "7cf1d081771c9fea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# save in labeled directories to apply ImageFolder",
   "id": "e1418a7df128e05c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
